my_str = """Original Model Test Accuracy: 66.86
> /run/user/1002/gvfs/sftp:host=132.66.53.79/home/adminubuntu/research/snl-amir/snl_finetune_freeze_alphas.py(141)main()
-> net = copy.deepcopy(base_classifier)
(Pdb) c
Original ReLU Count: 14621
Finetuning the model
Finetuning the model
Epoch: [0][0/196]	Time 0.994 (0.994)	Data 0.000 (0.000)	Loss 0.4477 (0.4477)	Acc@1 87.109 (87.109)	Acc@5 97.656 (97.656)
Epoch: [0][100/196]	Time 0.933 (0.934)	Data 0.000 (0.000)	Loss 0.5115 (0.4988)	Acc@1 85.156 (84.657)	Acc@5 98.828 (98.202)
Epoch: [0][195/196]	Loss 0.4699 (0.4990)	Acc@1 83.750 (84.698)	Acc@5 97.500 (98.146)
Test : [0/40]	Time 0.382 (0.382)	Data 0.099 (0.099)	Loss 1.3004 (1.3004)	Acc@1 70.703 (70.703)	Acc@5 87.500 (87.500)
Test Loss  (1.3680)	Test Acc@1 (66.800)	Test Acc@5 (89.100)
Epoch: [1][0/196]	Time 0.693 (0.693)	Data 0.000 (0.000)	Loss 0.4873 (0.4873)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [1][100/196]	Time 0.933 (0.932)	Data 0.000 (0.000)	Loss 0.4308 (0.4899)	Acc@1 87.109 (84.804)	Acc@5 98.047 (98.283)
Epoch: [1][195/196]	Loss 0.5015 (0.4926)	Acc@1 82.500 (84.792)	Acc@5 98.750 (98.218)
Test : [0/40]	Time 0.378 (0.378)	Data 0.096 (0.096)	Loss 1.2930 (1.2930)	Acc@1 70.703 (70.703)	Acc@5 87.891 (87.891)
Test Loss  (1.3646)	Test Acc@1 (66.890)	Test Acc@5 (89.270)
Epoch: [2][0/196]	Time 0.725 (0.725)	Data 0.000 (0.000)	Loss 0.4969 (0.4969)	Acc@1 84.375 (84.375)	Acc@5 98.047 (98.047)
Epoch: [2][100/196]	Time 0.954 (0.929)	Data 0.000 (0.000)	Loss 0.4230 (0.4967)	Acc@1 86.719 (84.638)	Acc@5 98.828 (98.260)
Epoch: [2][195/196]	Loss 0.4473 (0.4932)	Acc@1 88.750 (84.810)	Acc@5 98.750 (98.210)
Test : [0/40]	Time 0.378 (0.378)	Data 0.094 (0.094)	Loss 1.3012 (1.3012)	Acc@1 69.922 (69.922)	Acc@5 87.500 (87.500)
Test Loss  (1.3619)	Test Acc@1 (66.900)	Test Acc@5 (89.340)
Epoch: [3][0/196]	Time 0.713 (0.713)	Data 0.000 (0.000)	Loss 0.4491 (0.4491)	Acc@1 87.109 (87.109)	Acc@5 97.656 (97.656)
Epoch: [3][100/196]	Time 0.952 (0.941)	Data 0.000 (0.000)	Loss 0.4524 (0.4862)	Acc@1 86.328 (85.114)	Acc@5 98.828 (98.283)
Epoch: [3][195/196]	Loss 0.5907 (0.4920)	Acc@1 83.750 (84.960)	Acc@5 96.250 (98.184)
Test : [0/40]	Time 0.383 (0.383)	Data 0.101 (0.101)	Loss 1.3014 (1.3014)	Acc@1 71.094 (71.094)	Acc@5 87.891 (87.891)
Test Loss  (1.3610)	Test Acc@1 (66.890)	Test Acc@5 (89.280)
Epoch: [4][0/196]	Time 0.737 (0.737)	Data 0.000 (0.000)	Loss 0.4969 (0.4969)	Acc@1 85.156 (85.156)	Acc@5 97.266 (97.266)
Epoch: [4][100/196]	Time 0.958 (0.940)	Data 0.000 (0.000)	Loss 0.4005 (0.4848)	Acc@1 88.281 (85.017)	Acc@5 98.828 (98.147)
Epoch: [4][195/196]	Loss 0.4969 (0.4889)	Acc@1 86.250 (84.932)	Acc@5 97.500 (98.172)
Test : [0/40]	Time 0.381 (0.381)	Data 0.097 (0.097)	Loss 1.2774 (1.2774)	Acc@1 71.875 (71.875)	Acc@5 88.281 (88.281)
Test Loss  (1.3589)	Test Acc@1 (67.130)	Test Acc@5 (89.390)
Epoch: [5][0/196]	Time 0.707 (0.707)	Data 0.000 (0.000)	Loss 0.4901 (0.4901)	Acc@1 85.547 (85.547)	Acc@5 97.656 (97.656)
Epoch: [5][100/196]	Time 0.968 (0.947)	Data 0.000 (0.000)	Loss 0.4595 (0.4807)	Acc@1 84.766 (85.253)	Acc@5 98.438 (98.279)
Epoch: [5][195/196]	Loss 0.4110 (0.4812)	Acc@1 88.750 (85.078)	Acc@5 98.750 (98.304)
Test : [0/40]	Time 0.380 (0.380)	Data 0.106 (0.106)	Loss 1.2772 (1.2772)	Acc@1 70.703 (70.703)	Acc@5 88.281 (88.281)
Test Loss  (1.3535)	Test Acc@1 (67.000)	Test Acc@5 (89.330)
Epoch: [6][0/196]	Time 0.730 (0.730)	Data 0.000 (0.000)	Loss 0.3686 (0.3686)	Acc@1 89.453 (89.453)	Acc@5 98.438 (98.438)
Epoch: [6][100/196]	Time 0.998 (0.933)	Data 0.000 (0.000)	Loss 0.5008 (0.4834)	Acc@1 84.375 (85.075)	Acc@5 98.828 (98.244)
Epoch: [6][195/196]	Loss 0.3317 (0.4804)	Acc@1 91.250 (85.238)	Acc@5 98.750 (98.270)
Test : [0/40]	Time 0.376 (0.376)	Data 0.091 (0.091)	Loss 1.2835 (1.2835)	Acc@1 71.094 (71.094)	Acc@5 88.281 (88.281)
Test Loss  (1.3577)	Test Acc@1 (67.110)	Test Acc@5 (89.450)
Epoch: [7][0/196]	Time 0.688 (0.688)	Data 0.000 (0.000)	Loss 0.5295 (0.5295)	Acc@1 83.594 (83.594)	Acc@5 97.656 (97.656)
Epoch: [7][100/196]	Time 0.925 (0.928)	Data 0.000 (0.000)	Loss 0.5647 (0.4784)	Acc@1 83.203 (85.377)	Acc@5 97.656 (98.260)
Epoch: [7][195/196]	Loss 0.5463 (0.4816)	Acc@1 80.000 (85.288)	Acc@5 98.750 (98.232)
Test : [0/40]	Time 0.379 (0.379)	Data 0.090 (0.090)	Loss 1.2823 (1.2823)	Acc@1 71.094 (71.094)	Acc@5 88.281 (88.281)
Test Loss  (1.3557)	Test Acc@1 (66.960)	Test Acc@5 (89.270)
Epoch: [8][0/196]	Time 0.748 (0.748)	Data 0.000 (0.000)	Loss 0.4409 (0.4409)	Acc@1 86.328 (86.328)	Acc@5 97.656 (97.656)
Epoch: [8][100/196]	Time 0.958 (0.930)	Data 0.000 (0.000)	Loss 0.4815 (0.4708)	Acc@1 80.469 (85.512)	Acc@5 99.219 (98.287)
Epoch: [8][195/196]	Loss 0.6160 (0.4770)	Acc@1 86.250 (85.262)	Acc@5 96.250 (98.362)
Test : [0/40]	Time 0.374 (0.374)	Data 0.097 (0.097)	Loss 1.2965 (1.2965)	Acc@1 71.484 (71.484)	Acc@5 86.719 (86.719)
Test Loss  (1.3578)	Test Acc@1 (67.090)	Test Acc@5 (89.270)
Epoch: [9][0/196]	Time 0.694 (0.694)	Data 0.000 (0.000)	Loss 0.4829 (0.4829)	Acc@1 84.766 (84.766)	Acc@5 97.266 (97.266)
Epoch: [9][100/196]	Time 0.926 (0.925)	Data 0.000 (0.000)	Loss 0.4463 (0.4731)	Acc@1 87.109 (85.497)	Acc@5 98.828 (98.387)
Epoch: [9][195/196]	Loss 0.4080 (0.4759)	Acc@1 86.250 (85.406)	Acc@5 98.750 (98.328)
Test : [0/40]	Time 0.376 (0.376)	Data 0.098 (0.098)	Loss 1.2904 (1.2904)	Acc@1 70.312 (70.312)	Acc@5 87.891 (87.891)
Test Loss  (1.3549)	Test Acc@1 (67.010)	Test Acc@5 (89.330)
Epoch: [10][0/196]	Time 0.711 (0.711)	Data 0.000 (0.000)	Loss 0.4821 (0.4821)	Acc@1 84.375 (84.375)	Acc@5 97.266 (97.266)
Epoch: [10][100/196]	Time 0.951 (0.926)	Data 0.000 (0.000)	Loss 0.5491 (0.4669)	Acc@1 83.203 (85.686)	Acc@5 98.438 (98.422)
Epoch: [10][195/196]	Loss 0.7078 (0.4703)	Acc@1 82.500 (85.606)	Acc@5 92.500 (98.324)
Test : [0/40]	Time 0.371 (0.371)	Data 0.100 (0.100)	Loss 1.2865 (1.2865)	Acc@1 71.094 (71.094)	Acc@5 88.281 (88.281)
Test Loss  (1.3519)	Test Acc@1 (67.180)	Test Acc@5 (89.390)
Epoch: [11][0/196]	Time 0.696 (0.696)	Data 0.000 (0.000)	Loss 0.4271 (0.4271)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [11][100/196]	Time 0.923 (0.925)	Data 0.000 (0.000)	Loss 0.3919 (0.4765)	Acc@1 85.547 (85.160)	Acc@5 99.609 (98.271)
Epoch: [11][195/196]	Loss 0.5464 (0.4752)	Acc@1 85.000 (85.268)	Acc@5 100.000 (98.272)
Test : [0/40]	Time 0.374 (0.374)	Data 0.099 (0.099)	Loss 1.2789 (1.2789)	Acc@1 69.922 (69.922)	Acc@5 87.109 (87.109)
Test Loss  (1.3496)	Test Acc@1 (67.070)	Test Acc@5 (89.290)
Epoch: [12][0/196]	Time 0.738 (0.738)	Data 0.000 (0.000)	Loss 0.5015 (0.5015)	Acc@1 84.766 (84.766)	Acc@5 97.266 (97.266)
Epoch: [12][100/196]	Time 0.954 (0.926)	Data 0.000 (0.000)	Loss 0.4904 (0.4696)	Acc@1 85.938 (85.632)	Acc@5 98.828 (98.321)
Epoch: [12][195/196]	Loss 0.4075 (0.4709)	Acc@1 87.500 (85.550)	Acc@5 97.500 (98.328)
Test : [0/40]	Time 0.373 (0.373)	Data 0.100 (0.100)	Loss 1.2836 (1.2836)	Acc@1 71.094 (71.094)	Acc@5 88.281 (88.281)
Test Loss  (1.3487)	Test Acc@1 (67.340)	Test Acc@5 (89.500)
Epoch: [13][0/196]	Time 0.704 (0.704)	Data 0.000 (0.000)	Loss 0.4370 (0.4370)	Acc@1 87.500 (87.500)	Acc@5 98.438 (98.438)
Epoch: [13][100/196]	Time 0.924 (0.926)	Data 0.000 (0.000)	Loss 0.4348 (0.4666)	Acc@1 88.281 (85.814)	Acc@5 98.438 (98.418)
Epoch: [13][195/196]	Loss 0.3575 (0.4718)	Acc@1 91.250 (85.618)	Acc@5 97.500 (98.354)
Test : [0/40]	Time 0.374 (0.374)	Data 0.097 (0.097)	Loss 1.2918 (1.2918)	Acc@1 70.703 (70.703)	Acc@5 87.500 (87.500)
Test Loss  (1.3465)	Test Acc@1 (67.360)	Test Acc@5 (89.440)
Epoch: [14][0/196]	Time 0.766 (0.766)	Data 0.000 (0.000)	Loss 0.4790 (0.4790)	Acc@1 85.938 (85.938)	Acc@5 97.656 (97.656)
Epoch: [14][100/196]	Time 0.952 (0.927)	Data 0.000 (0.000)	Loss 0.3480 (0.4708)	Acc@1 90.625 (85.609)	Acc@5 98.828 (98.345)
Epoch: [14][195/196]	Loss 0.4477 (0.4689)	Acc@1 83.750 (85.830)	Acc@5 97.500 (98.312)
Test : [0/40]	Time 0.372 (0.372)	Data 0.106 (0.106)	Loss 1.2890 (1.2890)	Acc@1 70.703 (70.703)	Acc@5 88.281 (88.281)
Test Loss  (1.3480)	Test Acc@1 (67.170)	Test Acc@5 (89.510)
Epoch: [15][0/196]	Time 0.692 (0.692)	Data 0.000 (0.000)	Loss 0.4533 (0.4533)	Acc@1 82.812 (82.812)	Acc@5 98.047 (98.047)
Epoch: [15][100/196]	Time 0.927 (0.926)	Data 0.000 (0.000)	Loss 0.4825 (0.4709)	Acc@1 83.203 (85.524)	Acc@5 98.828 (98.453)
Epoch: [15][195/196]	Loss 0.5889 (0.4707)	Acc@1 80.000 (85.564)	Acc@5 97.500 (98.384)
Test : [0/40]	Time 0.372 (0.372)	Data 0.094 (0.094)	Loss 1.2811 (1.2811)	Acc@1 71.094 (71.094)	Acc@5 87.891 (87.891)
Test Loss  (1.3474)	Test Acc@1 (67.300)	Test Acc@5 (89.430)
Epoch: [16][0/196]	Time 0.719 (0.719)	Data 0.000 (0.000)	Loss 0.4707 (0.4707)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [16][100/196]	Time 0.952 (0.925)	Data 0.000 (0.000)	Loss 0.5503 (0.4665)	Acc@1 84.766 (85.879)	Acc@5 98.047 (98.360)
Epoch: [16][195/196]	Loss 0.2847 (0.4657)	Acc@1 90.000 (85.804)	Acc@5 100.000 (98.420)
Test : [0/40]	Time 0.373 (0.373)	Data 0.098 (0.098)	Loss 1.2800 (1.2800)	Acc@1 70.703 (70.703)	Acc@5 87.891 (87.891)
Test Loss  (1.3456)	Test Acc@1 (67.250)	Test Acc@5 (89.550)
Epoch: [17][0/196]	Time 0.690 (0.690)	Data 0.000 (0.000)	Loss 0.4381 (0.4381)	Acc@1 85.938 (85.938)	Acc@5 97.656 (97.656)
Epoch: [17][100/196]	Time 0.924 (0.926)	Data 0.000 (0.000)	Loss 0.5045 (0.4642)	Acc@1 83.594 (85.671)	Acc@5 96.875 (98.472)
Epoch: [17][195/196]	Loss 0.5517 (0.4642)	Acc@1 85.000 (85.694)	Acc@5 96.250 (98.400)
Test : [0/40]	Time 0.374 (0.374)	Data 0.092 (0.092)	Loss 1.2735 (1.2735)	Acc@1 71.484 (71.484)	Acc@5 88.281 (88.281)
Test Loss  (1.3475)	Test Acc@1 (67.170)	Test Acc@5 (89.490)
Epoch: [18][0/196]	Time 0.745 (0.745)	Data 0.000 (0.000)	Loss 0.4860 (0.4860)	Acc@1 88.281 (88.281)	Acc@5 97.656 (97.656)
Epoch: [18][100/196]	Time 0.949 (0.926)	Data 0.000 (0.000)	Loss 0.6302 (0.4555)	Acc@1 83.203 (86.042)	Acc@5 96.094 (98.379)
Epoch: [18][195/196]	Loss 0.4703 (0.4610)	Acc@1 86.250 (85.880)	Acc@5 98.750 (98.372)
Test : [0/40]	Time 0.372 (0.372)	Data 0.112 (0.112)	Loss 1.2748 (1.2748)	Acc@1 71.094 (71.094)	Acc@5 87.891 (87.891)
Test Loss  (1.3425)	Test Acc@1 (67.480)	Test Acc@5 (89.470)
Epoch: [19][0/196]	Time 0.712 (0.712)	Data 0.000 (0.000)	Loss 0.4348 (0.4348)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [19][100/196]	Time 0.925 (0.926)	Data 0.000 (0.000)	Loss 0.4441 (0.4539)	Acc@1 87.500 (86.115)	Acc@5 98.047 (98.468)
Epoch: [19][195/196]	Loss 0.4669 (0.4612)	Acc@1 91.250 (85.864)	Acc@5 97.500 (98.422)
Test : [0/40]	Time 0.375 (0.375)	Data 0.104 (0.104)	Loss 1.2797 (1.2797)	Acc@1 70.703 (70.703)	Acc@5 87.109 (87.109)
Test Loss  (1.3470)	Test Acc@1 (67.210)	Test Acc@5 (89.540)
Final best Prec@1 = 67.48%
Final best Prec@1 = 67.48%
"""
accs = [66.86]
for line in my_str.splitlines():
	if line.startswith('Test Loss'):
		test_acc = float(line.split(' ')[5].split('(')[-1].split(')')[0])
		accs.append(test_acc)

accs.append(67.48)
print(len(accs))
import matplotlib.pyplot as plt

plt.plot(accs, '-x', linewidth=3)
plt.xticks(range(len(accs)), ['snl-15k'] + [f'ours-epoch{i}' for i in range(len(accs) - 1)], rotation='vertical')
plt.grid(True)
plt.title('train betas; test accuracy vs epoch')
plt.ylabel('accuracy[%]')
plt.tight_layout()
plt.savefig('snl_alpha_freeze_output/betas_step.png')
